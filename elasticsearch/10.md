# 10. 대용량 처리를 위한 시스템 최적화

## 10.1 노드 실행환경과 JVM 옵션
* 엘라스틱서치와 루씬(jar - 라이브러리) 는 ES 인스턴스가 생성되면 JVM 위에서 함께 동작된다.
### 10.1.1 엘라스틱서치 릴리스 노트

### 10.1.2 실행시 자바8 이상을 사용해야 하는 이유
* 과거에 비해 CPU/메모리 자원이 넉넉하게 제공됨.
* 큰 물리 메모리 사용
```
- 기존 32비트 운영체제에서는 물리 메모리를 4GB(2^32) 밖에 인식하지 못하지만,
- 64비트에서는 수백GB(2^64)를 인식하는 것이 가능하다.
- 하지만 CPU상의 레지스터도 64비트로 동작해야 하기 때문에 하나의 CPU 명령어를 처리하는 데 필요한 레지스터 연산에도 32비트에 비해 2배 이상의 주소 공간이 필요해진다.
- 자바 및 JVM도 64비트를 제공하게 됨.
- 따라서 사용가능한 힙 메모리도 과거에 비해 더 많이 할당되는게 가능해 짐.
```
* 다수의 CPU 사용
```
- 기존의 멀티 스레드 기반의 프로그래밍은 다수의 CPU가 탑재된 환경에서는 오히려 비효율적인 경우가 있음.
- 자바8의 스트림/람다는 언어 차원에서 손쉽게 멀티 코어로 함수를 동작시킬 수 있음.
- 이러한 특수한 함수를 람다라 부르며, 람다를 이용해 로직을 작성하고 스트림에 입력하면 다수의 CPU에서 동시에 데이터가 처리되며, 모든 CPU에서 처리가 끝날 때 까지 결과를 기다리게 됨. (일종의 맵리듀스 처럼)
```

```JAVA
//간단한 람다 표현식
Stream<String> words = Stream.of("Java", "Magazine", "is", "the", "best");

Map<String, Long> letterToCount =
                      words.map(w -> w.split(""))  //[J,a,v,a],[M,a,g,..]
                          .flatMap(Arrays::stream)  //[J,a,v,a,M,a,g,..]
                          .collect(groupingBy(identity(), counting()));
```
* 이러한 과정은 언어 차원에서 블랙박스로 이루어짐. 람다식 하나만으로도 자바 8을 써야할 이유는 분명하다.

### 10.1.3 항상 최신 버전의 엘라스틱서치를 사용해야 하는 이유
### 10.1.4 자바8에서 제공하는 JVM 옵션

### 10.1.5 엘라스틱서치에 적용된 JVM 옵션
* ES는 분산 시스템의 특성상 스케일 인/아웃이 빈번하게 일어나며, 장애를 복구하거나 Reindex 작업에 의해 일어나는 데이터 리밸런싱에 의해 많은 메모리를 사용한다.
* 전체적인 성능 향상을 위해 다수의 JVM 옵션을 반드시 튜닝해야 한다.
* 하지만 ES는 다년간 이러한 문제를 다뤘으며, **JVM옵션도 대부분 최적화되어 제공한다.**
* jvm.option 파일에는 기본적으로 제공하는 JVM 힙 크기가 1GB로 설정되어있는데, 실제 운영환경에서는 이를 반드시 **더 큰 크기로 수정해야 한다.**
* 힙 크기 변경 외에는 기본 설정된 JVM 옵션을 그대로 사용하는 것이 좋다.
<br>

## 10.2 힙 크기를 32GB 이하로 유지해야 하는 이유
* ES는 메모리를 많이 사용하는 애플리케이션이다.
* 시스템에서 제공되는 물리 메모리를 JVM 힙에 할당해서 ES가 사용하도록 설정할 수 있음.
* 너무 작은 힙 크기는 OOM을 발생시킬 수 있으며, 반대로 너무 크면 FullGC가 발생할 때 STW를 발생시킬 수 있다.
### 10.2.1 엘라스틱서치와 힙 크기
* Xms(최소 힙)와 Xmx(최대 힙)는 같도록 권장한다. ( https://www.elastic.co/guide/en/elasticsearch/reference/7.1/heap-size.html )
* 운영체제에 50%의 메모리 공간을 보장하자.

#### !!!!루씬 캡쳐 추가 ####

```
- ES 샤드는 내부에 루씬을 가지고 있으며, 루씬은 세그먼트 생성/관리를 위해 커널 시스템 캐시를 최대한 많이 활용한다.
- 실시간 검색을 위해서는 루씬이 최대한 많은 시스템 캐시를 확보하도록 지원해야 한다.
- 시스템 캐시는 커널 내에 존재하는 운영체제가 갖고있는 메모리 공간
- 그러므로 물리적인 메모리 공간의 50% 정도는 운영체제가 자유롭게 사용하도록 할당하고,
- 나머지를 ES 힙으로 할당하는것이 적절하다.
```
* 자바 8 기반에서는 힙 크기를 32GB 이상 사용하지 말자
```
- 메모리가 128GB인 하드웨어로 가정
1] 64GB 힙을 가지는 엘라스틱서치 노드 1개
2] 32GB 힙을 가지는 엘라스틱서치 노드 2개
2를 권장한다.

- 모든 자바기반의 어플리케이션에서는 Object Pointer 정책이 모두 동일하게 적용된다.
- Object Pointer 정책은 객체의 메모리 번지를 표현하는 주솟값이다.
- 자바 JVM은 32비트 JVM과, 64비트 JVM이 별도로 제공된다.
- 주솟값은 각각 32,64가 아닌, 둘 다 기본적으로 32비트 주솟값을 가지고 동작한다.
- 그 이유는 모든 JVM이 기본적으로 32비트 Object Pointer를 사용하고 있기 떄문이다.
```

### 10.2.2 Ordinary Object Pointer
* 자바에서는 모든 객체가 힙 영역에 생성된다.
* 이렇게 생성된 객체는 모두 포인터를 가지고 있고, 이를 통해 객체에 접근한다.
* JVM은 힙 영역에 생성된 객체에 접근하기 위해 포인터의 주소를 OOP 라고 하는 특수한 자료구조로 만들어서 관리하고 있으며, 이러한 OOP 들은 CPU의 처리 단위에 따라 동작하는 방식이 약간씩 달라진다.
```
* 32비트 시스템 : 32비트(2^32)까지 표현할 수 있기 때문에 최대 4GB까지의 주소공간을 가리킬 수 있다.
* 64비트 시스템 : 64비트(2^32)까지 표현할 수 있기 때문에 이론상 18EB(엑사바이트) 까지의 주소공간을 가리킬 수 있다.

- 32비트 시스템은 하나의 포인터를 표현하기 위해 32비트가 필요하다.
- 32비트를 이용하면 최대 4GB의 메모리 주소밖에 가리킬 수 없는데, 이러한 이유로 4GB 메모리밖에 사용할 수 없다.
- 64비트의 경우, 메모리상 하나의 주소를 가리키는 포인터 1개를 64비트로 표현하다보니 많은 메모리 공간의 낭비가 발생한다.
- 기존보다 인식 가능한 물리적 메모리의 크기가 늘긴 했지만, 메모리의 물리적인 공간 활용성은 상대적으로 낮아짐.
- 그뿐 아니라 CPU 내부의 LLc, L1, L2 캐시들은 지속적으로 값의 이동이 일어나는데, 64비트가 더 큰 대역폭을 소모한다.
```
### 10.2.3 Compressed Ordinary Object Pointer
* JDK6에 최초 탑재 / JDK7부터는 기본 설정으로 변경.
```
- Compressed OOP는 포인터의 공간낭비를 줄이고, 좀 더 빠른 연산을 위해 포인터를 압축해서 표현하는 일종의 트릭
- 포인터가 객체의 정확한 메모리 주소를 가리키는게 아니라 상대적인 오브젝트 오프셋(Object Offtset)을 가리키도록 살짝 변형해서 동작시키는 것.
- 8비트면 256바이트의 물리주소 공간이 아니라, 256개의 객체를 가리킬 수 있게 함.
- 한 객체의 크기가 8비트라고 가정하면 기존보다 무려 8배나 큰 주소공간을 사용하는 것이 가능해진다.

- 자바는 데이터 타입에 따라 객체를 8비트(boolean)부터 64비트(Long)까지 8의 배수로 힙 메모리에 생성하기 때문에, 32비트만을 이용해도 최대 32GB까지의 힙 메모리 공간을 가리키는 것이 가능해진다.
```
* 결과적으로 64비트 시스템에서 Compressed OOP를 사용할 경우 포인터를 표현할 때 예외적으로 32비트 포인터를 사용해 동작한다.
* 하지만 이런 트릭은 **힙 크기가 32GB를 넘어가면 더는 사용할 수 없다.**
```
- JVM은 힙 크기가 32GB를 넘어가는 순간 Compressed OOP를 일반적인 64비트 OOP로 자동으로 변환한다.
- 이 경우 모든 Object Pointer는 64비트 기반으로 바뀌어서 동작하고, 32비트를 사용하는 이점을 모두 잃어버린다.
```
* 최근 하드웨어가 발달해서 100GB 이상 메모리 장비도 많지만, 자바 기반의 어플리케이션에서는 조금 다른 관점으로 생각해 봐야한다.

### 10.2.4 엘라스틱서치에서 힙 크기 설정하기
* Compressed OOP 외에도, 너무 큰 힙 크기는 STW의 저주에 빠지게 만든다.
* ES는 64비트 JVM / Compressed OOP 방식의 32GB 힙 크기를 가장 이상적인 구성으로 안내한다.
* 다양한 상황에서의 물리 메모리 설정
```
1] 적절한 성능의 서버
- 총 물리 메모리 : 64GB
- 운영체제 할당 : 32GB
- 엘라스틱서치 인스턴스 수 : 1개 (32GB)

2] 고성능 서버
- 총 물리 메모리 : 128GB
- 운영체제 할당 : 64GB
- 엘라스틱서치 인스턴스 수 : 2개 (각각 32GB)

3] 전문(Full Text) 검색을 주 목적
- 총 물리 메모리 : 128GB
- 운영체제 할당 : 96GB (128/4*3)
- 엘라스틱서치 인스턴스 수 : 1개 (32GB)
* 루씬의 역색인 구조를 사용하는 경우가 더 많음.
* 루씬이 시스템 캐시를 통해 메모리를 최대한으로 사용할 수 있게

4] 일반적인 데이터필드 (Not Analyzed) 에서 정렬/집계 작업
- 총 물리 메모리 : 128GB
- 운영체제 할당 : 96GB
- 엘라스틱서치 인스턴스 수 : 1개 (32GB)
* 숫자, 날짜, geo_point, keyword 같은 데이터 타입의 경우 필드가 별도의 분석 과정을 거치지 않음
* 정렬이나 집계 시 루씬의 DoValues를 사용하기 때문에 힙 공간은 거의 사용되지 않음.

5] 전문(Full Text) 필드(Analyzed) 에서 정렬/집계 작업
- 총 물리 메모리 : 128GB
- 운영체제 할당 : 64GB
- 엘라스틱서치 인스턴스 수 : 2개 (각각 32GB)
* 루씬의 DocValues를 사용할 수 없기 때문에 fielddata라는 힙 기반의 캐시를 사용해야 함.
* 연산에 많은 힙 메모리가 필요하므로, ES 인스턴스를 여러개 생성하는 방식
```

### 10.2.5 엘라스틱서치에서 Compressed OOP 사용하기
* 최신 JDK에서는 기본 설정으로 동작하기 때문에 단순히 힙 크기를 32GB 이하로 설정하기만 하면 된다.
#### !!!!확인해보기 ####

#### 10.2.5.1 Compressed OOP 사용
#### 10.2.5.2 Compressed OOP로 동작 가능한 Limit 값
#### 10.2.5.3 Zero-Based Compressed OOP
#### 10.2.5.4 엘라스틱서치 로그로 Compressed OOP 사용 여부 확인하기
#### !!!!확인해보기 ####

## 10.3 엘라스틱서치와 가상 메모리

### 10.3.1 가상 메모리
#### !!!!그림 추가 가상메모리 ####
* 만약 특정 어플리케이션이 대용량의 가상 메모리를 할당받아 사용한다면, 운영체제 성능에 큰 악영향을 끼칠 수 있다.
* OS차원에서 다양한 제약을 두게 된다.
* 리눅스는, ulimit 명령어를 이용해 어플리케이션별로 제한된 리소스의 한계를 확인할 수 있다.

#### !!!!그림 추가 ulimit ####
* 각 리소스는 설정 값을 가지며 최댓값을 조절할 수 있다 (root 권한 필요)
* 기본적으로 제공되는 설정값은 최소한의 안전장치이므로, **수정할 때에는 매우 신중해야 한다.**


### 10.3.2 JVM을 위한 가상 메모리

### 10.3.3 엘라스틱서치를 위한 vm.max_map_count 설정
* 자바 어플리케이션은 기본적으로 JVM을 통해 할당받은 힙 메모리만 사용할 수 있다.
* 루씬은 대용량의 세그먼트를 생성하고 관리하기 위해 많은 리소스를 필요로 한다.
* 루씬은 특별한 방식으로 이러한 제약을 회피하고 있다.
```
- 루씬은 내부적으로 자바에서 제공하는 NIO 기술을 활용한다.
- 이를 운영체제 커널에서 제공하는 mmap 시스템콜을 직접 호출할 수 있으며
- VM을 거치지 않고도 직접 커널 모드로 진입하기에 높은 성능을 낼 수 있다.
- 부수적인 이득으로 커널레벨의 파일 시스템 캐시를 사용할 수 있다.
- 이러한 이유로 ES에서는 힙 설정 시 운영체제에 50%의 물리 메모리를 양보하라 한 것이다.
- 결과적으로 ES는 자바 힙 메모리 뿐 아니라 운영체제에 할당된 물리 메모리도 사용할 수 있다.
```
* ES에서 루씬이 원활하게 동작하기 위해서는 가상 메모리 설정 중 mmap 크기 항목을 변경해야 한다.
* CentOS 7 버전은 기본적으로 가상 메모리에서 생성 가능한 mmap 개수가 65,530으로 설정돼있다.
```
$ cat /proc/sys/vm/max_map_count

65530
```
* ES는 초기 로딩(Bootstrap) 과정에서 수치가 **262,114 이하이면 오류 및 강제 종료시킨다.**
* 아래와 같이 변경할 수 있으며, 운영체제가 재부팅되면 기본값으로 초기화되기 때문에 영구적으로 /etc/sysctl.conf 파일에서 설정하는게 좋다.
```
$ sudo sysctl -w vm.max_map_count = 262144
```

## 10.4 분산환경에서의 메모리 스와핑
* ES 클러스터가 분산 시스템을 지향하고 대용량 데이터를 많이 처리하다 보니 시스템 리소스를 최대한 효율적으로 활용해야 한다.

### 10.4.1 메모리 스와핑
#### !!!!그림 붙이기 ####
* 운영체제 입장에서 스와핑은 많은 리소스를 사용하는 작업이다.

### 10.4.2 엘라스틱서치에서 스와핑을 비활성화해야 하는 이유
* ES가 동작하는데 필요한 메모리도 스와핑으로 언제든지 디스크로 스와핑될 수 있다.
* 노드 안정성에 치명적이기 때문에 이를 피해야 한다.
* ES포함 대부분의 분산시스템에서는 전체적인 클러스터의 안정성을 해치는 것보다는 문제가 발생한 노드가 강제로 종료되어 클러스터 구성에서 제외되는 편이 훨씬 더 효율적이다.
* 그러므로 ES에서는 **어떠한 대가를 치르더라도 스와핑이 절대 발생하지 않게 해야한다.**
<br>
* 클러스터를 구성하는 노드에는 가능한 ES만 단독으로 운영하는 것이 여러모로 유리하다.
* CentOS 7에서는 스와핑을 줄이기 위한 방법이 3가지 있다.
```
* 스와핑 비활성화 : $ sudo swapoff -a
* 스와핑 최소화 : $ sudo sysctl vm.swappiness=1
- 위 두 가지는 시스템 레벨, 루트권한 이다.
```
```
* memory_lock 설정
- elasticsearch.yml 의 bootstrap.memory_lock: true
- mlockall() 함수와 동일한 방식으로 어플리케이션 차원에서 스와핑을 최대한 방지할 수 있다.
- _nodes API를 이용해 memory_lock 설정 여부를 확인할 수 있다.
```
#### !!!!캡쳐 추가 ####

- 대부분의 설정 실패는 운영체제의 리소스 제한 설정이 주요 원인.
* ulimit 명령어로 unlimited로 변경하면 된다.
```
$ ulimit -l unlimited
```

## 10.5 시스템 튜닝 포인트
* 리눅스는 시스템 최적화를 위한 다양한 툴 제공
* ulimit : 유저 레벨의 최적화
```
- 운영체제에는 여러 어플리케이션이 동시에 실행될 수 있기 때문에 특정 어플리케이션이 리소스를 독점하지 못하도록 관리하는 것이 중요하다.
- ulimit 명령어는 어플리케이션이 실행될 때 얼만큼의 리소스를 할당받을 수 있는지에 대한 전반적 리소스 관리 수행
- 모든 어플리케이션에 적용된다.
```
* sysctl : 커널 레벨의 최적화
```
- 리눅스 내부에 존재하는 커널의 파라미터를 조절할 수 있도록 설정값 제공
```

### 10.5.1 어플리케이션에서 튜닝 가능한 리소스
#### 10.5.1.1 ulimit 명령어
#### 10.5.1.2 sysctl 명령어
#### 10.5.1.3 실행 중인 어플리케이션의 리소스 확인
#### !!!!엘라 프로세스 캡쳐 ####

### 10.5.2 ulimit 명령어를 이용한 유저 레벨의 튜닝
* 일반적으로는 기본 설정만 따라도 충분하며, 변경 작업은 신중하게 해야한다.
* 모든 어플리케이션에 적용되기에 숙지하지 않고 변경하면 대형 장애가 발생할 수 있다.

#### 10.5.2.1 ulimit 명령어
#### !!!!ulimit 캡쳐 ####

#### 10.5.2.2 소프트 설정과 하드 설정
* 내부적으로 soft와 hard가 있다.
* 소프트는 프로세스가 실행될 때 최초로 할당받는 값
* 하드는 운영 중에 리소스의 한계에 도달할 경우 추가로 할당받을 수 있는 값
* 이중으로 제한하는 이유는 처음부터 최대를 할당받으면 리소스 낭비가 심해질 수 있기 떄문
* ES는 많은 리소스를 사용하기에, 처음부터 Sa와 Ha를 같게 설정하자.

#### 10.5.2.3 ulimit 영구 설정
* /etc/security/limits.conf
#### !!!!캡쳐 ####

### 10.5.3 sysctl 명령어를 이용한 커널 레벨의 튜닝
* 함부로 수정할 경우 자칫 운영체제 전체가 심각한 불능 상태에 빠질 수 있으므로 항상 주의
#### !!!!캡쳐 넣기 + vm.max_map_count 변경된것 확인 ####

* 커널 파라미터를 수정하기 위해서는 -w 옵션으로 가능
```
$ sysctl -w 파라미터명 = 파라미터 값
$ vi /etc/sysctl.conf  # 영구적 저장
```

### 10.5.4 엘라스틱서치 노드 레벨의 튜닝
#### 10.5.4.1 Max Open File 한계 설정
* 특정 노드가 "Too many open files" 에러를 뱉음
* ES가 추가 리소스를 파일형태로 운영체제에 할당 요청을 했고, ulimit 제한에 걸려서 실패
* ES는 많은 소켓, 루씬은 많은 파일을 관리하므로 많이 제공되어야 함
* 설정값을 최소 65,536개 이상의 큰 값으로 변경하는것이 좋다.
```
$ ulimit -n 81920
$ vi /etc/security/limits.conf
```
#### 10.5.4.2 Max Thread 한계 설정
* ES는 스레드풀을 도입했으며, 이는 내부에 큐가 있어서 트래픽이 몰려도 데이터를 보관할 수 있다.
* 스레드풀 내부의 스레드 개수도 사용자가 직접 설정하는 것이 가능하다.
* 스레드풀 내부의 스레드 수는 처리량에 따라 유동적으로 변해야 하므로 마음껏 생성할 수 있도록 해주어야 한다.
```
$ ulimit -u 81920
$ 영구적도..
```
#### 10.5.4.3 네트워크 설정






# 결론
### 1] 엘라스틱 서치는 자바 8 사용
### 2] JVM은 힙 설정 제외는 건드리지 말것
### 3] heap 크기는 32 GB 이하로
### 4] vm.max_map_count = 262144
### 5] Memory 스와핑 비활성화 설정
### 6] ulimit은 어플리케이션에 공통 적용되므로 조심해서 설정하자
### 7] PM으로 받으면 좋을것 같습니다..!
